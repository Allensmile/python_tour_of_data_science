{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Course\n",
    "### &nbsp; &nbsp; &nbsp; MichaÃ«l Defferrard, Sept. 2016\n",
    "## Lecture 2: A Python Tour of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this short primer is to introduce the Python stack for Data Science. It is designed as a tour around the major Python packages used for the main computational tasks encountered in Data Science. Before starting, two notes:\n",
    "1. There exists faster / better ways to accomplish the presented computations. The goal is to present the packages.\n",
    "1. It is not meant to teach you (scientific) Python. I however tried to include the main construtions and idioms of the language and packages.\n",
    "\n",
    "A typical Data Science **pipeline**:\n",
    "1. Data acquisition\n",
    "    1. Importation\n",
    "    1. Cleaning\n",
    "    1. Exploration\n",
    "1. Data exploitation\n",
    "    1. Information extraction\n",
    "    1. Prediction\n",
    "\n",
    "A **motivating example**: predict whether a credit card client will default.\n",
    "* Binary classification task: client will default or not ($y=1$ if yes; $y=0$ if no).\n",
    "* 30'000 clients from Taiwan.\n",
    "* 23 numerical & categorical explanatory variables:\n",
    "    1. $x_1$: Amount of the given credit.\n",
    "    2. $x_2$: Gender (1 = male; 2 = female).\n",
    "    3. $x_3$: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "    4. $x_4$: Marital status (1 = married; 2 = single; 3 = others).\n",
    "    5. $x_5$: Age (year).\n",
    "    6. $x_6$ to $x_{11}$: History of past payment (monthly from September to April, 2005) (-1 = pay duly; 1 = payment delay for one month; ...; 9 = payment delay for nine months and above).\n",
    "    7. $x_{12}$ to $x_{17}$: Amount of bill statement (monthly from September to April, 2005).\n",
    "    8. $x_{18}$ to $x_{23}$: Amount of previous payment (monthly from September to April, 2005).\n",
    "* Found on the [UCI ML repository](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn import linear_model, metrics\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import time\n",
    "\n",
    "# Or notebook for interaction.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data acquisition\n",
    "\n",
    "* The world is messy: we got data from CSV, JSON, Excel, HDF5, SQL database.\n",
    "* Could also be: matlab, HTML/XML, web scraping, web APIs (e.g. Twitter Firhose), noSQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing from a database\n",
    "\n",
    "[SQLAlchemy](http://www.sqlalchemy.org/) to the rescue.\n",
    "* Abstraction between DBAPIs.\n",
    "    * Supported databases: SQLite, Postgresql, MySQL, Oracle, MS-SQL, Firebird, Sybase and others.\n",
    "* [SQL Expression Language](http://docs.sqlalchemy.org/en/rel_1_0/core/tutorial.html).\n",
    "* [Object Relational Mapper (ORM)](http://docs.sqlalchemy.org/en/rel_1_0/orm/tutorial.html).\n",
    "\n",
    "TODO: show some ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///data/payments.sqlite', echo=False)\n",
    "\n",
    "# Infer from existing DB.\n",
    "metadata = sqlalchemy.MetaData()\n",
    "metadata.reflect(engine)\n",
    "\n",
    "# An SQL SELECT statement.\n",
    "table = metadata.tables.get('payments')\n",
    "op = sqlalchemy.sql.select([table])\n",
    "engine.echo = True\n",
    "result = engine.execute(op)\n",
    "engine.echo = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show some lines.\n",
    "for row in result.fetchmany(size=10):\n",
    "    print('ID: {:2d}, payments: {}'.format(row[0], row[1:]))\n",
    "result.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some raw SQL.\n",
    "paid = 1000\n",
    "op = sqlalchemy.sql.text('SELECT payments.\"ID\", payments.\"PAY6\" FROM payments WHERE payments.\"PAY6\" = {}'.format(paid))\n",
    "result = engine.execute(op).fetchall()\n",
    "print('{} clients paid {} in April 2005'.format(len(result), paid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Merging data sources\n",
    "\n",
    "Put some [pandas](http://pandas.pydata.org/) in our Python !\n",
    "* Import / export data from / to various sources.\n",
    "* Data frames manipulations: slicing, dicing, grouping.\n",
    "* And many more !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    demographics = pd.read_csv(folder + 'demographics.csv', skiprows=[0], index_col=0)\n",
    "    delays = pd.read_excel(folder + 'delays.xls', skiprows=[0], index_col=0)\n",
    "    bills = pd.read_hdf(folder + 'bills.hdf5', 'bills')\n",
    "    payments = pd.read_sql('payments', engine, index_col='ID')\n",
    "\n",
    "    target = pd.read_json(folder + 'target.json', typ='series', orient='index')\n",
    "    target = pd.DataFrame(target, columns=['DEFAULT'])\n",
    "\n",
    "    return pd.concat([demographics, delays, bills, payments, target], axis=1)\n",
    "\n",
    "data = get_data('data/')\n",
    "attributes = data.columns.tolist()\n",
    "\n",
    "# Tansform from numerical to categorical variable.\n",
    "data['SEX'] = data['SEX'].astype('category')\n",
    "data['SEX'].cat.categories = ['MALE', 'FEMALE']\n",
    "data['MARRIAGE'] = data['MARRIAGE'].astype('category')\n",
    "data['MARRIAGE'].cat.categories = ['UNK', 'MARRIED', 'SINGLE', 'OTHERS']\n",
    "data['EDUCATION'] = data['EDUCATION'].astype('category')\n",
    "data['EDUCATION'].cat.categories = ['UNK', 'GRAD SCHOOL', 'UNIVERSITY', 'HIGH SCHOOL', 'OTHERS', 'UNK1', 'UNK2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[:6, ['LIMIT', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'DEFAULT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.iloc[:5, 4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.iloc[:5, 11:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export as an [HTML table](./subset.html) for manual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[:1000].to_html('subset.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data cleaning\n",
    "\n",
    "The most boring part. But the most time intensive !\n",
    "\n",
    "TODO: show a study. Which one was it, KDnuggets ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marital status\n",
    "* Should be either 1 (married), 2 (single) or 3 (others).\n",
    "* Let's *assume* the 0 represents errors when collecting the data and remove those clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data['MARRIAGE'].value_counts())\n",
    "data = data[data['MARRIAGE'] != 'UNK']\n",
    "data['MARRIAGE'] = data['MARRIAGE'].cat.remove_unused_categories()\n",
    "print('\\nWe are left with {} clients\\n'.format(data.shape))\n",
    "print(data['MARRIAGE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Education\n",
    "* Should be either 1 (graduate school), 2 (university), 3 (high school) or 4 (others).\n",
    "* Let's *assume* the 0, 5, 6 are dubious, but do not invalidate the data. Keep them as they may have predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data['EDUCATION'].value_counts())\n",
    "data.loc[data['EDUCATION']=='UNK1', 'EDUCATION'] = 'UNK'\n",
    "data.loc[data['EDUCATION']=='UNK2', 'EDUCATION'] = 'UNK'\n",
    "data['EDUCATION'] = data['EDUCATION'].cat.remove_unused_categories()\n",
    "print(data['EDUCATION'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data exploration\n",
    "\n",
    "* Get descriptive statistics.\n",
    "* Plot informative figures.\n",
    "* Verify some intuitive correlations.\n",
    "\n",
    "TODO: further exploration with [statsmodels](http://statsmodels.sourceforge.net/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attributes_numerical = ['LIMIT', 'AGE']\n",
    "attributes_numerical.extend(attributes[11:23])\n",
    "data.loc[:, attributes_numerical].describe().astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'AGE'].plot.hist(bins=20, figsize=(15,5))\n",
    "ax = data.iloc[:, 11:17].plot.box(logy=True, figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentage = data[data.DEFAULT == 1].shape[0] / data.shape[0] * 100\n",
    "print('Percentage of defaults: {:.2f}%'.format(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who's more susceptible to default, males or females ?\n",
    "Statistical signifiance could be tested with [scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(data['SEX'], data['DEFAULT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition**: people who pay late present a higher risk of defaulting. Let's verify ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group = data.groupby('DELAY1').mean()\n",
    "group['DEFAULT'].plot(grid=True, figsize=(15,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Pre-processing\n",
    "\n",
    "Back to [NumPy](http://www.numpy.org/), the fundamental package for scientific computing with Python. It provides multi-dimensional arrays, data types and linear algebra routines.\n",
    "\n",
    "1. Transform data types.\n",
    "1. Data normalization.\n",
    "    * Some algorithms expect data to be centered and scaled.\n",
    "    * Some will train faster.\n",
    "1. Train / test splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Back to numeric values.\n",
    "# Note: in a serious project, these should be treated as categories.\n",
    "data['SEX'].cat.categories = [-1, 1]\n",
    "data['SEX'] = data['SEX'].astype(np.int)\n",
    "data['MARRIAGE'].cat.categories = [-1, 1, 0]\n",
    "data['MARRIAGE'] = data['MARRIAGE'].astype(np.int)\n",
    "data['EDUCATION'].cat.categories = [-2, 2, 1, 0, -1]\n",
    "data['EDUCATION'] = data['EDUCATION'].astype(np.int)\n",
    "\n",
    "data['DEFAULT'] = data['DEFAULT'] * 2 - 1  # [0,1] --> [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Observations and targets.\n",
    "X = data.values[:,:23]\n",
    "y = data.values[:,23]\n",
    "n, d = X.shape\n",
    "print('The data is a {} with {} samples of dimensionality {}.'.format(type(X), n, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Center and scale.\n",
    "# Note: on a serious project, should be done after train / test split.\n",
    "X = X.astype(np.float)\n",
    "X -= X.mean(axis=0)\n",
    "X /= X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training and testing sets.\n",
    "test_size = 10000\n",
    "print('Split: {} testing and {} training samples'.format(test_size, y.size - test_size))\n",
    "perm = np.random.permutation(y.size)\n",
    "X_test  = X[perm[:test_size]]\n",
    "X_train = X[perm[test_size:]]\n",
    "y_test  = y[perm[:test_size]]\n",
    "y_train = y[perm[test_size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Visualization\n",
    "\n",
    "[matplotlib](http://matplotlib.org/) is the goto 2D plotting library.\n",
    "\n",
    "TODO: interactive (widget, [Bokeh](http://bokeh.pydata.org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(data.values[:,4],'.')\n",
    "plt.title('Original')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(X[:,4],'.')\n",
    "plt.title('Centered and scaled')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 A first predictive model\n",
    "\n",
    "The ingredients of a Machine Learning (ML) model:\n",
    "1. Predictive function: $f(x) = xw^T + b$ (a linear transformation)\n",
    "1. Error function: $E = \\sum_{i=1}^n \\left( f(x_i) - y_i \\right)^2 = \\| f(X) - y \\|_2^2$ (least squares)\n",
    "1. Regularization (optional): $R = \\|w\\|_2^2$ (Thikonov)\n",
    "1. Loss / objective function: $L = E + \\alpha R$\n",
    "\n",
    "Our model has a sole hyper-parameter, $\\alpha \\geq 0$, which controls the shrinkage\n",
    "\n",
    "A Machine Learning (ML) problem can often be cast as a (convex or smooth) optimization problem:\n",
    "\n",
    "1. Optimization problem\n",
    "$$\\hat{w} = \\operatorname*{arg min}_w \\| Xw + b - y \\|_2^2 + \\alpha \\|w\\|_2^2$$\n",
    "1. Gradient\n",
    "$$\\frac{\\partial L}{\\partial{w}} = 2 X^T (Xw+b-y) + 2\\alpha w$$\n",
    "$$\\frac{\\partial L}{\\partial{b}} = 2 \\sum_{i=1}^n (x_iw+b-y_i) = 2 \\sum_{i=1}^n (x_iw-y_i) + 2n \\cdot b$$\n",
    "1. Closed-form solution:\n",
    "$$\\frac{\\partial L}{\\partial{w}} = 0 \\ \\rightarrow \\ 2 X^T X\\hat{w} + 2\\alpha \\hat{w} = 2 X^T y - 2 X^T b \\ \\rightarrow \\ \\hat{w} = (X^T X + \\alpha I)^{-1} X^T (y-b)$$\n",
    "$$\\frac{\\partial L}{\\partial{b}} = 0 \\ \\rightarrow \\ 2n\\hat{b} = 2\\sum_{i=1}^n (y_i) - \\underbrace{2\\sum_{i=1}^n (x_iw)}_{=0} \\ \\rightarrow \\ \\hat{b} = \\frac1n I^T y$$\n",
    "\n",
    "What if the resulting problem is non-smooth ? See the [PyUNLocBoX](http://pyunlocbox.readthedocs.io), a convex optimization toolbox which implements [proximal splitting methods](https://en.wikipedia.org/wiki/Proximal_gradient_method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Take a *symbolic* derivative\n",
    "\n",
    "[SymPy](http://www.sympy.org/) is our computer algebra system (CAS) of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, w, b, a = sp.symbols('x y w b a')\n",
    "L = (X*w + b - y)**2 + a*w**2\n",
    "dLdw = sp.diff(L, w)\n",
    "dLdb = sp.diff(L, b)\n",
    "print('L = {}'.format(L))\n",
    "print('  dL/dw = {}'.format(dLdw))\n",
    "print('  dL/db = {}'.format(dLdb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Build the classifier\n",
    "\n",
    "We solely use the [NumPy](http://www.numpy.org/) linear algebra capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ridge_regression(object):\n",
    "    \"\"\"Our ML model.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0):\n",
    "        \"The model's constructor. Initialize the hyper-parameters.\"\n",
    "        self.a = alpha\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return the predicted class given the features.\"\"\"\n",
    "        return np.sign(X.dot(self.w) + self.b)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Learn the model's parameters given the training data, the closed-form way.\"\"\"\n",
    "        n, d = X.shape\n",
    "        self.b = np.mean(y)\n",
    "        Ainv = np.linalg.inv(X.T.dot(X) + self.a * np.identity(d))\n",
    "        self.w = Ainv.dot(X.T).dot(y - self.b)\n",
    "\n",
    "    def loss(self, X, y, w=None, b=None):\n",
    "        w = self.w if w is None else w\n",
    "        b = self.b if b is None else b\n",
    "        return np.linalg.norm(X.dot(w) + b - y) + self.a * np.linalg.norm(w, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"Our evaluation metric, the classification accuracy.\"\"\"\n",
    "    return np.sum(y_pred == y_true) / y_true.size\n",
    "\n",
    "def evaluate(model):\n",
    "    t = time.process_time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy(y_pred, y_test)\n",
    "    loss = model.loss(X_test, y_test)\n",
    "    t = time.process_time() - t\n",
    "    print('accuracy: {:.2f}%, loss: {:.2f}, time: {:.2f}ms'.format(acc*100, loss, t*1000))\n",
    "\n",
    "alpha = 1e-2*n\n",
    "evaluate(ridge_regression(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_lapack(self, X, y):\n",
    "    \"\"\"Better way (numerical stability): solve the linear system with LAPACK.\"\"\"\n",
    "    n, d = X.shape\n",
    "    self.b = np.mean(y)\n",
    "    A = X.T.dot(X) + self.a * np.identity(d)\n",
    "    b = X.T.dot(y - self.b)\n",
    "    self.w = np.linalg.solve(A, b)\n",
    "\n",
    "# Observe that Python is a dynamic language.\n",
    "ridge_regression.fit = fit_lapack\n",
    "\n",
    "evaluate(ridge_regression(alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Learning as optimization\n",
    "\n",
    "Feel the power of [SciPy](https://www.scipy.org/) ! It provides higher-level algorithms, e.g. optimization, interpolation, signal processing, sparse matrices, decompositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ridge_regression_optimize(ridge_regression):\n",
    "    \n",
    "    def __init__(self, alpha=0, method=None):\n",
    "        super().__init__(alpha)\n",
    "        self.method = method\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fitted with a general purpose optimization algorithm.\"\"\"\n",
    "        from scipy.optimize import minimize\n",
    "        n, d = X.shape\n",
    "        self.b = np.mean(y)\n",
    "        \n",
    "        f = lambda w: self.loss(X, y, w)\n",
    "        \n",
    "        def jac(w):\n",
    "            A = X.dot(w) + self.b - y\n",
    "            return 2 * X.T.dot(A) + 2 * self.a * w\n",
    "            \n",
    "        w0 = np.random.normal(size=d)\n",
    "        res = minimize(f, w0, method=self.method, jac=jac)\n",
    "        self.w = res.x\n",
    "\n",
    "#evaluate(ridge_regression_optimize(alpha=1e-2*n))\n",
    "evaluate(ridge_regression_optimize(alpha, method='Nelder-Mead'))\n",
    "evaluate(ridge_regression_optimize(alpha, method='BFGS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Automatic differentiation\n",
    "\n",
    "[autograd](https://github.com/HIPS/autograd/) is our tool of choice for [automatic differentation](https://en.wikipedia.org/wiki/Automatic_differentiation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 ML models made easier\n",
    "\n",
    "Tired of writing algorithms ? Try [scikit-learn](http://scikit-learn.org), which provides many tools for data mining and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.Ridge(alpha)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = np.sign(model.predict(X_test))\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print('accuracy: {:.2f}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "acc = model.score(X_test, y_test)\n",
    "print('accuracy: {:.2f}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Deep Learning\n",
    "\n",
    "Two Python low-level libraries:\n",
    "1. [TensorFlow](https://www.tensorflow.org/)\n",
    "1. [Theano](http://deeplearning.net/software/theano/)\n",
    "\n",
    "Higher-level libraries:\n",
    "1. [Keras](https://keras.io/): TensorFlow & Theano backends\n",
    "1. [Lasagne](http://lasagne.readthedocs.io): Theano backend\n",
    "1. [Blocks](http://blocks.readthedocs.io): Theano backend\n",
    "1. [TFLearn](http://tflearn.org): TensorFlow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(output_dim=46, input_dim=23, activation='relu'))\n",
    "model.add(keras.layers.Dense(output_dim=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train/2+0.5, nb_epoch=5, batch_size=32)\n",
    "\n",
    "classes = model.predict_classes(X_test, batch_size=32)\n",
    "proba = model.predict_proba(X_test, batch_size=32)\n",
    "loss_acc = model.evaluate(X_test, y_test/2+0.5, batch_size=32)\n",
    "\n",
    "print('\\n\\nTesting set: {}'.format(loss_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Is Python slow ?\n",
    "\n",
    "As Python is an interpreted language, its executation can be slow compared to compiled languages.\n",
    "We have two ways around it:\n",
    "1. Compile it to machine code. [Numba](http://numba.pydata.org) is our Just-in-Time (JIT) compiler of choice. An alternative would be [PyPy](http://pypy.org), but it does not support NumPy and lacks behind Cython. Or [Jython](http://www.jython.org) which runs Python on the Java platform, but is Python 2 only.\n",
    "1. Use specialized wrapper libraries. E.g. NumPy gives a wrapper to BLAS / LAPACK implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy_numpy(y_pred, y_true):\n",
    "    \"\"\"Using NumPy, implemented in C.\"\"\"\n",
    "    return accuracy(y_pred, y_true)\n",
    "\n",
    "def accuracy_python(y_pred, y_true):\n",
    "    \"\"\"Plain Python implementation.\"\"\"\n",
    "    num_total = 0\n",
    "    num_correct = 0\n",
    "    for y_pred_i, y_true_i in zip(y_pred, y_true):\n",
    "        num_total += 1\n",
    "        if y_pred_i == y_true_i:\n",
    "            num_correct += 1\n",
    "    return num_correct / num_total\n",
    "    \n",
    "from numba import jit\n",
    "# Decorator, same as accuracy_numba = jit(accuracy_python)\n",
    "\n",
    "@jit\n",
    "def accuracy_numba(y_pred, y_true):\n",
    "    \"\"\"Plain Python implementation, compiled by LLVM through Numba.\"\"\"\n",
    "    num_total = 0\n",
    "    num_correct = 0\n",
    "    for y_pred_i, y_true_i in zip(y_pred, y_true):\n",
    "        num_total += 1\n",
    "        if y_pred_i == y_true_i:\n",
    "            num_correct += 1\n",
    "    return num_correct / num_total\n",
    "\n",
    "%timeit accuracy_numpy(y_test, y_test)\n",
    "%timeit accuracy_python(y_test, y_test)\n",
    "%timeit accuracy_numba(y_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
